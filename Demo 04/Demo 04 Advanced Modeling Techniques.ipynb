{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setup Packages"
      ],
      "metadata": {
        "id": "NKOtkxj3SPwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30eSX38oSY49",
        "outputId": "dd33cf7f-102c-4cc2-ea38-3ebb1bf83f2f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from langdetect import detect\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, TimeDistributed\n",
        "from keras.models import load_model, Model\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "ga2F3tLJPkly"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load Title Column"
      ],
      "metadata": {
        "id": "3h_xqMOwTGh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Online Content.csv', usecols=['title'])"
      ],
      "metadata": {
        "id": "qe3x0e1eTG8d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Map Detected Language"
      ],
      "metadata": {
        "id": "txRz-aDNTKsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "language_map = {'en': 0, 'fr': 1, 'es': 2, 'de': 3, 'it': 4}\n",
        "languages = []"
      ],
      "metadata": {
        "id": "WONIkJ4aTK3P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for title in df['title']:\n",
        "    try:\n",
        "        lang = detect(title)\n",
        "        lang_label = language_map.get(lang, -1)\n",
        "    except Exception as e:\n",
        "        lang_label = -1\n",
        "    languages.append(lang_label)\n",
        "\n",
        "language_labels = np.array(languages)\n",
        "\n",
        "np.save('language_labels.npy', language_labels)"
      ],
      "metadata": {
        "id": "37E1q4RhTLbl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Load Data"
      ],
      "metadata": {
        "id": "iuyOOdPyTN2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load('audio.npy')\n",
        "y_speech = np.load('labels.npy')\n",
        "y_language = np.load('language_labels.npy')\n",
        "\n",
        "y_language_onehot = to_categorical(y_language, num_classes=5)\n",
        "\n",
        "X_train, X_val, y_speech_train, y_speech_val, y_lang_train, y_lang_val = train_test_split(\n",
        "    X, y_speech, y_language_onehot, test_size=0.2, random_state=44)"
      ],
      "metadata": {
        "id": "cWPpiyMFTOJQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Load Pre-trained Model"
      ],
      "metadata": {
        "id": "Nvm-C500TVCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = load_model('New_ASR_model.keras')"
      ],
      "metadata": {
        "id": "TE3kJTdrOt1H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Step 6: Updating Model Architecture"
      ],
      "metadata": {
        "id": "BJ9xBZwDTdXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer from the existing pretrained model\n",
        "input_layer = pretrained_model.input\n",
        "\n",
        "# Use output of the last LSTM layer from the pretrained model\n",
        "lstm_layer = pretrained_model.layers[-2].output\n",
        "\n",
        "# Task 1: Speech Recognition Output\n",
        "speech_output = TimeDistributed(Dense(y_speech.shape[2], activation='softmax'), name='speech_output')(lstm_layer)\n",
        "\n",
        "# Task 2: Language Detection Output\n",
        "language_output = Dense(y_language_onehot.shape[1], activation='softmax', name='language_output')(lstm_layer[:, -1])\n",
        "\n",
        "# Create the new Model instance\n",
        "new_model = Model(inputs=input_layer, outputs=[speech_output, language_output])\n",
        "\n",
        "# Compile the new model\n",
        "new_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss={'speech_output': 'categorical_crossentropy', 'language_output': 'categorical_crossentropy'},\n",
        "                  metrics=['accuracy'],\n",
        "                  loss_weights={'speech_output': 0.7, 'language_output': 0.3})"
      ],
      "metadata": {
        "id": "XMwK05ovOpS6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Train Model"
      ],
      "metadata": {
        "id": "56yM5U1pTij2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = new_model.fit(\n",
        "    X_train,\n",
        "    {'speech_output': y_speech_train, 'language_output': y_lang_train},\n",
        "    validation_data=(X_val, {'speech_output': y_speech_val, 'language_output': y_lang_val}),\n",
        "    epochs=10,\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDe4CFOlP0tf",
        "outputId": "de4a407e-89e0-4009-9b9a-bf4dcb431d57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 14s 2s/step - loss: 1.9424 - speech_output_loss: 1.8477 - language_output_loss: 2.1634 - speech_output_accuracy: 0.0021 - language_output_accuracy: 0.0125 - val_loss: 1.7318 - val_speech_output_loss: 1.7184 - val_language_output_loss: 1.7630 - val_speech_output_accuracy: 0.0035 - val_language_output_accuracy: 0.0500\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.6685 - speech_output_loss: 1.6833 - language_output_loss: 1.6339 - speech_output_accuracy: 0.0106 - language_output_accuracy: 0.0125 - val_loss: 1.4873 - val_speech_output_loss: 1.5760 - val_language_output_loss: 1.2804 - val_speech_output_accuracy: 0.0340 - val_language_output_accuracy: 0.9500\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 1.4308 - speech_output_loss: 1.5464 - language_output_loss: 1.1610 - speech_output_accuracy: 0.0377 - language_output_accuracy: 0.9375 - val_loss: 1.2664 - val_speech_output_loss: 1.4623 - val_language_output_loss: 0.8092 - val_speech_output_accuracy: 0.0340 - val_language_output_accuracy: 0.9500\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2305 - speech_output_loss: 1.4367 - language_output_loss: 0.7494 - speech_output_accuracy: 0.0377 - language_output_accuracy: 0.9375 - val_loss: 1.1296 - val_speech_output_loss: 1.3751 - val_language_output_loss: 0.5566 - val_speech_output_accuracy: 0.0340 - val_language_output_accuracy: 0.9500\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 1.1096 - speech_output_loss: 1.3533 - language_output_loss: 0.5408 - speech_output_accuracy: 0.0377 - language_output_accuracy: 0.9375 - val_loss: 1.0388 - val_speech_output_loss: 1.3073 - val_language_output_loss: 0.4124 - val_speech_output_accuracy: 0.0340 - val_language_output_accuracy: 0.9500\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 1.0267 - speech_output_loss: 1.2883 - language_output_loss: 0.4162 - speech_output_accuracy: 0.0377 - language_output_accuracy: 0.9375 - val_loss: 0.9786 - val_speech_output_loss: 1.2546 - val_language_output_loss: 0.3346 - val_speech_output_accuracy: 0.0355 - val_language_output_accuracy: 0.9500\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 192ms/step - loss: 0.9728 - speech_output_loss: 1.2397 - language_output_loss: 0.3500 - speech_output_accuracy: 0.0404 - language_output_accuracy: 0.9375 - val_loss: 0.9396 - val_speech_output_loss: 1.2151 - val_language_output_loss: 0.2966 - val_speech_output_accuracy: 0.0380 - val_language_output_accuracy: 0.9500\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 0.9395 - speech_output_loss: 1.2050 - language_output_loss: 0.3201 - speech_output_accuracy: 0.0421 - language_output_accuracy: 0.9375 - val_loss: 0.9145 - val_speech_output_loss: 1.1872 - val_language_output_loss: 0.2783 - val_speech_output_accuracy: 0.0390 - val_language_output_accuracy: 0.9500\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 186ms/step - loss: 0.9188 - speech_output_loss: 1.1813 - language_output_loss: 0.3063 - speech_output_accuracy: 0.0410 - language_output_accuracy: 0.9375 - val_loss: 0.8992 - val_speech_output_loss: 1.1688 - val_language_output_loss: 0.2702 - val_speech_output_accuracy: 0.0430 - val_language_output_accuracy: 0.9500\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.9064 - speech_output_loss: 1.1664 - language_output_loss: 0.2997 - speech_output_accuracy: 0.0446 - language_output_accuracy: 0.9375 - val_loss: 0.8903 - val_speech_output_loss: 1.1572 - val_language_output_loss: 0.2675 - val_speech_output_accuracy: 0.0455 - val_language_output_accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Save Trained Model"
      ],
      "metadata": {
        "id": "A4NEA4r-Tpu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.save('multitask_ASR_model.keras')"
      ],
      "metadata": {
        "id": "pk7l9PFQOqiQ"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}