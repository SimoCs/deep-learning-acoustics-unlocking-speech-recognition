{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setup Packages"
      ],
      "metadata": {
        "id": "NKOtkxj3SPwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30eSX38oSY49",
        "outputId": "3565b600-799d-40cf-d52b-ed59dc6025e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from langdetect import detect\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, TimeDistributed\n",
        "from keras.models import load_model, Model\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "ga2F3tLJPkly"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load Title Column"
      ],
      "metadata": {
        "id": "3h_xqMOwTGh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Online Content.csv', usecols=['title'])"
      ],
      "metadata": {
        "id": "qe3x0e1eTG8d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Map Detected Language"
      ],
      "metadata": {
        "id": "txRz-aDNTKsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "language_map = {'en': 0, 'fr': 1, 'es': 2, 'de': 3, 'it': 4}\n",
        "languages = []"
      ],
      "metadata": {
        "id": "WONIkJ4aTK3P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for title in df['title']:\n",
        "    try:\n",
        "        lang = detect(title)\n",
        "        lang_label = language_map.get(lang, -1)\n",
        "    except Exception as e:\n",
        "        lang_label = -1\n",
        "    languages.append(lang_label)\n",
        "\n",
        "language_labels = np.array(languages)\n",
        "\n",
        "np.save('language_labels.npy', language_labels)"
      ],
      "metadata": {
        "id": "37E1q4RhTLbl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Load Data"
      ],
      "metadata": {
        "id": "iuyOOdPyTN2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load('audio.npy')\n",
        "y_speech = np.load('labels.npy')\n",
        "y_language = np.load('language_labels.npy')\n",
        "\n",
        "y_language_onehot = to_categorical(y_language, num_classes=5)\n",
        "\n",
        "X_train, X_val, y_speech_train, y_speech_val, y_lang_train, y_lang_val = train_test_split(\n",
        "    X, y_speech, y_language_onehot, test_size=0.2, random_state=44)"
      ],
      "metadata": {
        "id": "cWPpiyMFTOJQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Load Pre-trained Model"
      ],
      "metadata": {
        "id": "Nvm-C500TVCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = load_model('New_ASR_model.keras')"
      ],
      "metadata": {
        "id": "TE3kJTdrOt1H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Step 6: Updating Model Architecture"
      ],
      "metadata": {
        "id": "BJ9xBZwDTdXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer from the existing pretrained model\n",
        "input_layer = pretrained_model.input\n",
        "\n",
        "# Use output of the last LSTM layer from the pretrained model\n",
        "lstm_layer = pretrained_model.layers[-2].output\n",
        "\n",
        "# Task 1: Speech Recognition Output\n",
        "speech_output = TimeDistributed(Dense(y_speech.shape[2], activation='softmax'), name='speech_output')(lstm_layer)\n",
        "\n",
        "# Task 2: Language Detection Output\n",
        "language_output = Dense(y_language_onehot.shape[1], activation='softmax', name='language_output')(lstm_layer[:, -1])\n",
        "\n",
        "# Create the new Model instance\n",
        "new_model = Model(inputs=input_layer, outputs=[speech_output, language_output])\n",
        "\n",
        "# Compile the new model\n",
        "new_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss={'speech_output': 'categorical_crossentropy', 'language_output': 'categorical_crossentropy'},\n",
        "                  metrics=['accuracy'],\n",
        "                  loss_weights={'speech_output': 0.7, 'language_output': 0.3})"
      ],
      "metadata": {
        "id": "XMwK05ovOpS6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Train Model"
      ],
      "metadata": {
        "id": "56yM5U1pTij2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = new_model.fit(\n",
        "    X_train,\n",
        "    {'speech_output': y_speech_train, 'language_output': y_lang_train},\n",
        "    validation_data=(X_val, {'speech_output': y_speech_val, 'language_output': y_lang_val}),\n",
        "    epochs=10,\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDe4CFOlP0tf",
        "outputId": "09a856d8-1cb6-4c64-c751-6ef0885c1997"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 13s 2s/step - loss: 1.7190 - speech_output_loss: 1.9002 - language_output_loss: 1.2963 - speech_output_accuracy: 0.0000e+00 - language_output_accuracy: 0.1750 - val_loss: 1.4990 - val_speech_output_loss: 1.7430 - val_language_output_loss: 0.9295 - val_speech_output_accuracy: 0.0000e+00 - val_language_output_accuracy: 0.9500\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 355ms/step - loss: 1.4910 - speech_output_loss: 1.7291 - language_output_loss: 0.9352 - speech_output_accuracy: 0.0099 - language_output_accuracy: 0.9500 - val_loss: 1.3100 - val_speech_output_loss: 1.5931 - val_language_output_loss: 0.6494 - val_speech_output_accuracy: 0.0455 - val_language_output_accuracy: 0.9500\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.3108 - speech_output_loss: 1.5851 - language_output_loss: 0.6707 - speech_output_accuracy: 0.0429 - language_output_accuracy: 0.9500 - val_loss: 1.1655 - val_speech_output_loss: 1.4701 - val_language_output_loss: 0.4549 - val_speech_output_accuracy: 0.0455 - val_language_output_accuracy: 0.9500\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 362ms/step - loss: 1.1735 - speech_output_loss: 1.4665 - language_output_loss: 0.4899 - speech_output_accuracy: 0.0429 - language_output_accuracy: 0.9500 - val_loss: 1.0667 - val_speech_output_loss: 1.3772 - val_language_output_loss: 0.3423 - val_speech_output_accuracy: 0.0455 - val_language_output_accuracy: 0.9500\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.0792 - speech_output_loss: 1.3773 - language_output_loss: 0.3834 - speech_output_accuracy: 0.0429 - language_output_accuracy: 0.9500 - val_loss: 1.0021 - val_speech_output_loss: 1.3086 - val_language_output_loss: 0.2869 - val_speech_output_accuracy: 0.0455 - val_language_output_accuracy: 0.9500\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 1.0145 - speech_output_loss: 1.3095 - language_output_loss: 0.3260 - speech_output_accuracy: 0.0429 - language_output_accuracy: 0.9500 - val_loss: 0.9589 - val_speech_output_loss: 1.2575 - val_language_output_loss: 0.2622 - val_speech_output_accuracy: 0.0455 - val_language_output_accuracy: 0.9500\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 0.9692 - speech_output_loss: 1.2582 - language_output_loss: 0.2949 - speech_output_accuracy: 0.0429 - language_output_accuracy: 0.9500 - val_loss: 0.9295 - val_speech_output_loss: 1.2198 - val_language_output_loss: 0.2521 - val_speech_output_accuracy: 0.0455 - val_language_output_accuracy: 0.9500\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 351ms/step - loss: 0.9368 - speech_output_loss: 1.2201 - language_output_loss: 0.2757 - speech_output_accuracy: 0.0429 - language_output_accuracy: 0.9500 - val_loss: 0.9102 - val_speech_output_loss: 1.1933 - val_language_output_loss: 0.2495 - val_speech_output_accuracy: 0.0470 - val_language_output_accuracy: 0.9500\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 354ms/step - loss: 0.9134 - speech_output_loss: 1.1923 - language_output_loss: 0.2627 - speech_output_accuracy: 0.0450 - language_output_accuracy: 0.9500 - val_loss: 0.8980 - val_speech_output_loss: 1.1753 - val_language_output_loss: 0.2509 - val_speech_output_accuracy: 0.0485 - val_language_output_accuracy: 0.9500\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.8970 - speech_output_loss: 1.1728 - language_output_loss: 0.2535 - speech_output_accuracy: 0.0484 - language_output_accuracy: 0.9500 - val_loss: 0.8902 - val_speech_output_loss: 1.1631 - val_language_output_loss: 0.2534 - val_speech_output_accuracy: 0.0420 - val_language_output_accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Save Trained Model"
      ],
      "metadata": {
        "id": "A4NEA4r-Tpu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.save('multitask_ASR_model.keras')"
      ],
      "metadata": {
        "id": "pk7l9PFQOqiQ"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}