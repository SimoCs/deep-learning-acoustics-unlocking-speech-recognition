# Readme
Automatic Speech Recognition (ASR) models for use in Pluralsight **Unlocking Speech Recognition: Deep Learning in Acoustics** video course. Below, you can find a list of technologies used in the demos, along with their respective versions:

| Technology    | Version |
| -------- | ------- |
| Python | 3.10.12 |
| PyTorch | 2.2.2  |
| Hugging Face Transformers  | 4.39.1  |
| Librosa    | 0.10.1  |
| JiWER    | 3.0.3 |
| NumPy    | 1.26.4 |
| Pandas   | 2.2.1  |
| gTTS    | 2.5.1  |
| Torchaudio    | 2.2.2 |
| NLTK    | 3.8.1 |
| Google Colab    | Latest Version |

- [Demo 01 Preprocessing Steps for Audio Data](https://github.com/SimoCs/deep-learning-acoustics-unlocking-speech-recognition/tree/main/Demo%2001)
- [Demo 02 Building and Training a Basic ASR Model](https://github.com/SimoCs/deep-learning-acoustics-unlocking-speech-recognition/tree/main/Demo%2002)
- [Demo 03 Evaluating and Improving Model Performance](https://github.com/SimoCs/deep-learning-acoustics-unlocking-speech-recognition/tree/main/Demo%2003)
- [Demo 04 Advanced Modeling Techniques](https://github.com/SimoCs/deep-learning-acoustics-unlocking-speech-recognition/tree/main/Demo%2004)
- [Demo 05 Enhance Model Robustness Against Noisy Data](https://github.com/SimoCs/deep-learning-acoustics-unlocking-speech-recognition/tree/main/Demo%2005)
- [Demo 06 Enhancing an ASR Model With Advanced Techniques](https://github.com/SimoCs/deep-learning-acoustics-unlocking-speech-recognition/tree/main/Demo%2006)

# Connect with me
I am a very curious individual. Learning is my drive in life, and technology is the language I speak!

- Twitter: [@MEchout](https://twitter.com/MEchout)
- LinkedIn: [Mohamed Echout](https://www.linkedin.com/in/mohamed-echout/)
